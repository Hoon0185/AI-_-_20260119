{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-26T07:48:30.888357800Z",
     "start_time": "2026-01-26T07:48:26.800816100Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# 1. 모델 로드 (YOLOv8 나노 모델 예시)\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# 2. ONNX 포맷으로 변환\n",
    "model.export(format=\"onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.5  Python-3.13.11 torch-2.9.1+cpu CPU (13th Gen Intel Core i5-1335U)\n",
      "Model summary (fused): 73 layers, 11,126,745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from 'best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (21.5 MB)\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m Ultralytics requirement ['onnxslim>=0.1.71'] not found, attempting AutoUpdate...\n",
      "WARNING Retry 1/2 failed: Command 'pip install --no-cache-dir \"onnxslim>=0.1.71\" ' returned non-zero exit status 1.\n",
      "WARNING Retry 2/2 failed: Command 'pip install --no-cache-dir \"onnxslim>=0.1.71\" ' returned non-zero exit status 1.\n",
      "WARNING \u001B[31m\u001B[1mrequirements:\u001B[0m  Command 'pip install --no-cache-dir \"onnxslim>=0.1.71\" ' returned non-zero exit status 1.\n",
      "'pip'()    ,    , \n",
      "  .\n",
      "\n",
      "\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m starting export with onnx 1.20.1 opset 22...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Code\\PythonProject\\.venv\\Lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\utils.py:1447: OnnxExporterWarning: Exporting to ONNX opset version 22 is not supported. by 'torch.onnx.export()'. The highest opset version supported is 20. To use a newer opset version, consider 'torch.onnx.export(..., dynamo=True)'. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING \u001B[34m\u001B[1mONNX:\u001B[0m simplifier failure: No module named 'onnxslim'\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m export success  3.0s, saved as 'best.onnx' (42.7 MB)\n",
      "\n",
      "Export complete (4.0s)\n",
      "Results saved to \u001B[1mC:\\Code\\AI-_-_20260119\\PG\u001B[0m\n",
      "Predict:         yolo predict task=detect model=best.onnx imgsz=640 \n",
      "Validate:        yolo val task=detect model=best.onnx imgsz=640 data=C:/Users/User/Documents/GitHub/AI-_-_20260119/KMJ/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'best.onnx'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "69f66d785e0a07ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
